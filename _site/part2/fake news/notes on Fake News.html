<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>digitacity by brettneese</title>

    <link rel="stylesheet" href="/assets/css/style.css?v=5a23d87d136d7228cfc5c83b56da9803f0643068">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>digitacity</h1>
        <p></p>

       
        
        
        
      </header>
      <section>

      
<p>in the Columbia Journalism Review, Yochai Benkler, Robert Faris, Hal Roberts, and Ethan Zuckerman — basically everyone who’s ever said anything moderately useful about the Internet — have a new piece dissecting the information/media ecosystem during the 2016 election. while the data itself is concerning though not surprising: they conclude, essentially, that Breitbart and right-wing media sources formed a “internally coherent, relatively insulated knowledge community, reinforcing the shared worldview of readers.”</p>

<p>that’s troubling for all the obvious reasons. but what’s really really interesting about their analysis is that it starts with the network. that’s, of course, to be expected with Benkler and Zuckerman. traditionally we might have gone about scavenging through individual articles, or reading books, or examining newsreels. this is an analysis of the <em>network as whole</em>, as the fundamental unit of study: they studied specifically the</p>

<blockquote>
  <p>hyperlinking patterns, social media sharing patterns on Facebook and Twitter, and topic and language patterns in the content of the 1.25 million stories, published by 25,000 sources over the course of the election.</p>
</blockquote>

<p>the network is the building block of their new epistemological ecosystem. i don’t think it’s appropriate to simply deny the legitimacy of this “knowledge community” merely because it seems to fail to refer to what might otherwise be called “facts.” as they note:</p>

<blockquote>
  <p>rather than “fake news” in the sense of wholly fabricated falsities, many of the most-shared stories can more accurately be understood as disinformation: the purposeful construction of true or partly true bits of information into a message that is, at its core, misleading.</p>
</blockquote>

<p>the net effect of this fabrication is that even completely “fake” stories have real effective political and social power, in spite of their complete fabrication (after all, Donald Trump is our new president.) how ought we consider this kind of information: information which is either misleading or fails to refer to anything substantive but yet has substantive consequences?</p>

<p>this is not a new problem for epistemology: plato loathed the sophists as those who “speak falsely.” 20th century philosophy took up the issue of false speech as well, with the fathers of analytic philosophy such Bertrand Russel grappling with it. propaganda, too, is nothing new: Nazis used it, the Soviets used it, even the United States has used it. we’ve long grappled with the disastrous effects of false information while, of course, taking the assumption that “false” information as somehow morally bad for-granted; since at least Plato, there was a concern for a universal, knowable truth, as something obtainable and understandable by humans; and setting the stage for that journey has been one of the primary goals of our political systems.</p>

<p>the enlightenment-era answer to this problem has always been to grant society the power of free speech and the freedom of the press (notably: not free expression, at least in the united states.) our republics countered this problem formally by splitting key decision-making entities into a system of checks and balances; even our formal sciences are grounded upon the idea of peer review and independent verification as essential to the epistemological project.</p>

<p>the problem with this is that the assumption is the disinformation or propaganda would come from some central authority, and the powers of these distributed forces would serve to dialectically correct it. those structures don’t seem to operate the same way any more: to say nothing of their utter failure when met with mass media in the twentieth century, the problem with networked modes of knowledge is precisely that these patterns form as an emergent property of the network itself:</p>

<blockquote>
  <p>The fact that these asymmetric patterns of attention were similar on both Twitter and Facebook suggests that human choices and political campaigning, not one company’s algorithm, were responsible for the patterns we observe. These patterns might be the result of a coordinated campaign, but they could also be an emergent property of decentralized behavior, or some combination of both. Our data to this point cannot distinguish between these alternatives.</p>
</blockquote>

<p>to again be clear, it’s not as if I’m suggesting in any of my thoughts on this that it was the internet as a <em>technical system</em> that is causing this fundamental rift. rather, it’s emerging out of the behavior of humans on the network and within the network who have yet to develop political structures through which to counter the network’s most adverse effects. the problem with fake news is that it exists in the mode of networks yet utilizes the epistemological structures of text. what grants fake news its legitimacy is found within the structures of text itself: the conception of text as a concrete representation of the world while operating in a ecosystem which is inherently viral and fluid. what grants it’s corruptive power is that it remains stuck in a political system that recognizes knowledge formation and dispersion as a relatively centralized and private activity.</p>

<p>one point I will vehemently disagree with the authors on is this conception that the “the primary explanation of such asymmetric polarization is more likely politics and culture than technology.” i don’t think it’s appropriate to separate the political and the cultural from the technological. i understand for their work here this is probably necessary, but when zoomed out a bit I can’t for the life of me think through where one ends and the other begins. they’re all part of the same ecosystem. that’s the fundamental insight that Donna Haraway touched on that’s so critical to understanding our current social reality: cyborgs don’t care about boundary projects. they exist in a disperse, dynamic and chaotic web of understanding and interacting with the world. yet they were birthed out of a social reality that very much seeks to atomize, distinguish, and delineate things. the combination of those two forces allows isolated, insular communities of knowledge to quickly form, just as easily as it allows communities to react and respond to new information. something along those lines appears to be what’s happening vis-a-vis “fake news.”</p>



      </section>
      <footer>
        
        <p>This project is maintained by <a href="http://github.com/brettneese">brettneese</a></p>
        
      </footer>
    </div>
    <script src="/assets/js/scale.fix.js"></script>


  
  </body>
</html>